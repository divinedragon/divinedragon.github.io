---
date: 2024-10-15
title: "tarsier â€” Vision utilities for web interaction agents"
slug: repository-tarsier
tags: [ repository, open-source, github, tools, video, ai, llm, agents ]
---



If you've tried using an LLM to automate web interactions, you've probably run into questions like:

* How should you feed the webpage to an LLM? (e.g. HTML, Accessibility Tree, Screenshot)
* How do you map LLM responses back to web elements?
* How can you inform a text-only LLM about the page's visual structure?

At [Reworkd][2], we iterated on all these problems across tens of thousands of real web tasks to build a powerful perception system for web agents... [Tarsier][1]! In the video below, we use Tarsier to provide webpage perception for a minimalistic GPT-4 LangChain web agent.

<video src="https://github.com/reworkd/tarsier/assets/50181239/af12beda-89b5-4add-b888-d780b353304b" width="100%" controls></video>



  [1]: https://github.com/reworkd/tarsier
  [2]: https://www.reworkd.ai/
