---
date: "2024-10-16"
title: "Qwen2-VL - Multi-modal LLM from Alibaba"
slug: "repository-qwen2-llm"
tags: [ repository, open-source, github, ai, llm, image ]
---



[Qwen2-VL][1] is the multimodal large language model series developed by Qwen team, Alibaba Cloud.

After a year's relentless efforts, today we are thrilled to release [Qwen2-VL][1]! [Qwen2-VL][1] is the latest version of the vision language models in the Qwen model families.

![Qwen2-VL details][2]

Key Enhancements:

* **SoTA understanding of images of various resolution & ratio**: Qwen2-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.
* **Understanding videos of 20min+**: with the online streaming capabilities, Qwen2-VL can understand videos over 20 minutes by high-quality video-based question answering, dialog, content creation, etc.
* **Agent that can operate your mobiles, robots, etc.**: with the abilities of complex reasoning and decision making, Qwen2-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.
* **Multilingual Support**: to serve global users, besides English and Chinese, Qwen2-VL now supports the understanding of texts in different languages inside images, including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.



   [1]: https://github.com/QwenLM/Qwen2-VL
   [2]: https://camo.githubusercontent.com/a98a801cab554fd20099a2c3fcce4597f45866b31f5d78f391c91196f4a3e57e/68747470733a2f2f7169616e77656e2d7265732e6f73732d616363656c65726174652d6f766572736561732e616c6979756e63732e636f6d2f5177656e322d564c2f7177656e325f766c5f6672616d65776f726b2e6a7067
